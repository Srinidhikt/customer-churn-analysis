{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Customer Churn Analysis (Telecom Industry)\n",
    "\n",
    "## Objective\n",
    "Predict churn and derive actionable strategies to retain users in a highly competitive telecom environment.\n",
    "\n",
    "## Tools\n",
    "- Python (Scikit-learn, SHAP/ELI5)\n",
    "- SQL for data aggregation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "import matplotlib.pyplot as plt\n",
    "import shap\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Load and Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example dataset (replace with your telecom data)\n",
    "data = pd.DataFrame({\n",
    "    'customer_id': range(1, 21),\n",
    "    'call_duration': np.random.randint(50, 500, 20),\n",
    "    'complaints': np.random.randint(0, 5, 20),\n",
    "    'recharge_freq': np.random.randint(1, 10, 20),\n",
    "    'monthly_charges': np.random.randint(100, 1000, 20),\n",
    "    'paperless_billing': np.random.choice([0, 1], 20),\n",
    "    'payment_method': np.random.choice([0, 1, 2], 20),\n",
    "    'churn': np.random.choice([0, 1], 20, p=[0.7, 0.3])\n",
    "})\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Train-Test Split and Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(columns=['customer_id','churn'])\n",
    "y = data['churn']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Train Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(max_iter=1000)\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Model Evaluation (Confusion Matrix & ROC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "\n",
    "fpr, tpr, _ = roc_curve(y_test, model.predict_proba(X_test_scaled)[:,1])\n",
    "roc_auc = auc(fpr, tpr)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "plt.plot([0,1],[0,1],'--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Explainability (SHAP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer = shap.LinearExplainer(model, X_train_scaled)\n",
    "shap_values = explainer.shap_values(X_test_scaled)\n",
    "\n",
    "shap.summary_plot(shap_values, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Customer Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['churn_prob'] = model.predict_proba(scaler.transform(X))[:,1]\n",
    "data['segment'] = pd.cut(data['churn_prob'],\n",
    "                        bins=[-0.01, 0.3, 0.7, 1.0],\n",
    "                        labels=['Loyal','Dormant','At Risk'])\n",
    "data[['customer_id','churn_prob','segment']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Save Model & Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('telecom_churn_model.pkl','wb') as f:\n",
    "    pickle.dump(model,f)\n",
    "\n",
    "data.to_csv('SAMPLE CHURN.csv', index=False)\n",
    "print(\"Files saved: telecom_churn_model.pkl, SAMPLE CHURN.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}


import pickle
with open("telecom_churn.pkl", "wb") as f:
    pickle.dump(model, f)

print("âœ… Model saved as telecom_churn.pkl")
